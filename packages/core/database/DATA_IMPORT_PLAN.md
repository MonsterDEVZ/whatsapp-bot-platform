# –ü–ª–∞–Ω –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î_–º–∞—à–∏–Ω—ã.pdf

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω –∏–º–ø–æ—Ä—Ç–∞ "–≥—Ä—è–∑–Ω—ã—Ö" –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ **–ë–î_–º–∞—à–∏–Ω—ã.pdf** –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

---

## üìã –û–±–∑–æ—Ä –∑–∞–¥–∞—á–∏

**–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:** `/–¢–ó/–ë–î_–º–∞—à–∏–Ω—ã.pdf`
**–§–æ—Ä–º–∞—Ç:** PDF-—Ç–∞–±–ª–∏—Ü–∞ —Å 39 —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è ~900+ –∑–∞–ø–∏—Å–µ–π
**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:** ID, –ú–∞—Ä–∫–∞, –ú–æ–¥–µ–ª—å, –ì–æ–¥, –û–ø–∏—Å–∞–Ω–∏–µ

**–¶–µ–ª—å:** –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã:
- `brands` - –º–∞—Ä–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
- `models` - –º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –º–∞—Ä–∫–∞–º
- `body_types` - —Ç–∏–ø—ã –∫—É–∑–æ–≤–∞ (–∏–∑–≤–ª–µ—á—å –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è)
- `patterns` - –Ω–∞–ª–∏—á–∏–µ –ª–µ–∫–∞–ª –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

---

## üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–º–ø–æ—Ä—Ç–∞

### –≠—Ç–∞–ø 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PDF

**–ó–∞–¥–∞—á–∞:** –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PDF –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (CSV/JSON)

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥:**

```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ PDF
# –û–ø—Ü–∏–∏:
# 1. pdfplumber - —Ö–æ—Ä–æ—à –¥–ª—è —Ç–∞–±–ª–∏—Ü
# 2. tabula-py - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ç–∞–±–ª–∏—Ü –≤ PDF
# 3. PyPDF2 + —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
```

**–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞:**

```python
import pdfplumber
import pandas as pd
from pathlib import Path

def extract_tables_from_pdf(pdf_path: str) -> pd.DataFrame:
    """
    –ò–∑–≤–ª–µ—á—å –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ PDF –∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –æ–¥–∏–Ω DataFrame.

    Returns:
        DataFrame —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏: ID, –ú–∞—Ä–∫–∞, –ú–æ–¥–µ–ª—å, –ì–æ–¥, –û–ø–∏—Å–∞–Ω–∏–µ
    """
    all_data = []

    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            table = page.extract_table()

            if table:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞)
                for row in table[1:]:
                    if row[0]:  # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ ID –Ω–µ –ø—É—Å—Ç–æ–π
                        all_data.append({
                            'id': row[0],
                            'brand': row[1],
                            'model': row[2],
                            'year': row[3],
                            'description': row[4]
                        })

    df = pd.DataFrame(all_data)
    return df

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
df = extract_tables_from_pdf('../–¢–ó/–ë–î_–º–∞—à–∏–Ω—ã.pdf')
df.to_csv('raw_vehicle_data.csv', index=False)
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** –§–∞–π–ª `raw_vehicle_data.csv` —Å ~900 —Å—Ç—Ä–æ–∫–∞–º–∏

---

### –≠—Ç–∞–ø 2: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

**–ó–∞–¥–∞—á–∞:** –û—á–∏—Å—Ç–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–º—É –≤–∏–¥—É

**–ü—Ä–æ–±–ª–µ–º—ã –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–ø–æ –∞–Ω–∞–ª–∏–∑—É –ë–î_–º–∞—à–∏–Ω—ã.pdf):**

1. **–ù–µ–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–∞—Ä–æ–∫:** "Honda" vs "HONDA" vs "—Ö–æ–Ω–¥–∞"
2. **–°–º–µ—à–∞–Ω–Ω—ã–µ —è–∑—ã–∫–∏:** –ö–∏—Ä–∏–ª–ª–∏—Ü–∞ –∏ –ª–∞—Ç–∏–Ω–∏—Ü–∞
3. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≥–æ–¥–æ–≤:** –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º –ø–æ–ª–µ–º "–ì–æ–¥"
4. **–ù–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:** "—Å –±–æ—Ä—Ç–∞–º–∏ –ª–µ–≤—ã–π —Ä—É–ª—å", "–ø–æ–ª–Ω—ã–π —Å–∞–ª–æ–Ω", "3 —Ä—è–¥–∞"
5. **–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ:** –û–¥–Ω–∞ –∏ —Ç–∞ –∂–µ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑

**–ö–æ–¥ –æ—á–∏—Å—Ç–∫–∏:**

```python
import re
from typing import Optional, Tuple

def normalize_brand(brand: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ä–∫–∏.

    –ü—Ä–∏–º–µ—Ä—ã:
        "HONDA" -> "Honda"
        "–¢–æ–π–æ—Ç–∞" -> "Toyota"
        "–º–µ—Ä—Å–µ–¥–µ—Å-–±–µ–Ω—Ü" -> "Mercedes-Benz"
    """
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    brand_mapping = {
        "–¢–æ–π–æ—Ç–∞": "Toyota",
        "–•–æ–Ω–¥–∞": "Honda",
        "–ë–ú–í": "BMW",
        "–ú–µ—Ä—Å–µ–¥–µ—Å": "Mercedes-Benz",
        # ... —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–ª—è –≤—Å–µ—Ö –º–∞—Ä–æ–∫
    }

    brand = brand.strip()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ
    if brand in brand_mapping:
        return brand_mapping[brand]

    # Capitalize first letter of each word
    return brand.title()


def extract_body_type_from_description(description: str) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ—á—å —Ç–∏–ø –∫—É–∑–æ–≤–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è.

    –ü—Ä–∏–º–µ—Ä—ã:
        "—Å –±–æ—Ä—Ç–∞–º–∏ –ª–µ–≤—ã–π —Ä—É–ª—å" -> None (–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)
        "—Å–µ–¥–∞–Ω –ª–µ–≤—ã–π —Ä—É–ª—å" -> "sedan"
        "–≤–Ω–µ–¥–æ—Ä–æ–∂–Ω–∏–∫ 3 —Ä—è–¥–∞" -> "suv"
    """
    if not description:
        return None

    desc_lower = description.lower()

    # –°–ª–æ–≤–∞—Ä—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    body_type_keywords = {
        'sedan': ['—Å–µ–¥–∞–Ω'],
        'hatchback': ['—Ö—ç—Ç—á–±–µ–∫', '—Ö–µ—Ç—á–±–µ–∫'],
        'suv': ['–≤–Ω–µ–¥–æ—Ä–æ–∂–Ω–∏–∫', '–¥–∂–∏–ø'],
        'minivan': ['–º–∏–Ω–∏–≤—ç–Ω', '–º–∏–Ω–∏–≤–µ–Ω', '–ø–æ–ª–Ω—ã–π —Å–∞–ª–æ–Ω', '3 —Ä—è–¥–∞'],
        'truck': ['–≥—Ä—É–∑–æ–≤–æ–π', '–≥—Ä—É–∑–æ–≤–∏–∫', '–∫–∞–±–∏–Ω–∞'],
        'coupe': ['–∫—É–ø–µ', '–∫—É–ø—ç'],
        'wagon': ['—É–Ω–∏–≤–µ—Ä—Å–∞–ª'],
    }

    for body_code, keywords in body_type_keywords.items():
        if any(kw in desc_lower for kw in keywords):
            return body_code

    return None


def parse_year_range(year_str: str) -> Tuple[Optional[int], Optional[int]]:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –≥–æ–¥–∞ –∏–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –ª–µ—Ç.

    –ü—Ä–∏–º–µ—Ä—ã:
        "2020" -> (2020, 2020)
        "2018-2022" -> (2018, 2022)
        "–¥–æ 2006–≥" -> (None, 2006)
        "-" -> (None, None)
    """
    if not year_str or year_str.strip() in ['-', '']:
        return (None, None)

    # –£–±–∏—Ä–∞–µ–º "–≥", "–≥.", –ø—Ä–æ–±–µ–ª—ã
    year_str = re.sub(r'[–≥–≥\.]', '', year_str).strip()

    # –î–∏–∞–ø–∞–∑–æ–Ω: 2018-2022
    if '-' in year_str:
        parts = year_str.split('-')
        try:
            year_from = int(parts[0]) if parts[0] else None
            year_to = int(parts[1]) if parts[1] else None
            return (year_from, year_to)
        except ValueError:
            return (None, None)

    # –û–¥–Ω–æ —á–∏—Å–ª–æ: 2020
    try:
        year = int(year_str)
        return (year, year)
    except ValueError:
        return (None, None)


def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –≤—Å–µ –æ—á–∏—Å—Ç–∫–∏ –∫ DataFrame."""
    df_clean = df.copy()

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ä–æ–∫
    df_clean['brand'] = df_clean['brand'].apply(normalize_brand)

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫—É–∑–æ–≤–∞
    df_clean['body_type'] = df_clean['description'].apply(extract_body_type_from_description)

    # –ü–∞—Ä—Å–∏–Ω–≥ –≥–æ–¥–æ–≤
    years = df_clean['year'].apply(parse_year_range)
    df_clean['year_from'] = years.apply(lambda x: x[0])
    df_clean['year_to'] = years.apply(lambda x: x[1])

    # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–µ–π (–ø–æ –º–∞—Ä–∫–µ, –º–æ–¥–µ–ª–∏, –≥–æ–¥–∞–º)
    df_clean = df_clean.drop_duplicates(
        subset=['brand', 'model', 'year_from', 'year_to'],
        keep='first'
    )

    return df_clean

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
df_raw = pd.read_csv('raw_vehicle_data.csv')
df_clean = clean_dataframe(df_raw)
df_clean.to_csv('cleaned_vehicle_data.csv', index=False)
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** –§–∞–π–ª `cleaned_vehicle_data.csv` —Å –æ—á–∏—â–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

---

### –≠—Ç–∞–ø 3: –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

**–ó–∞–¥–∞—á–∞:** –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ PostgreSQL —Å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏

**–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π:**

1. **–°–æ–∑–¥–∞—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –º–∞—Ä–æ–∫** (`brands`)
2. **–°–æ–∑–¥–∞—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ç–∏–ø–æ–≤ –∫—É–∑–æ–≤–∞** (`body_types`) - –µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω
3. **–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏** (`models`)
4. **–°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å–∏ –ª–µ–∫–∞–ª** (`patterns`) –¥–ª—è tenant

**–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞:**

```python
from sqlalchemy.orm import Session
from database.models import Tenant, Brand, BodyType, Model, Pattern, ProductCategory
from database.config import get_sync_session
import pandas as pd

def import_brands(df: pd.DataFrame, session: Session) -> dict:
    """
    –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–∏.

    Returns:
        –°–ª–æ–≤–∞—Ä—å {brand_name: brand_id}
    """
    unique_brands = df['brand'].unique()
    brand_map = {}

    for brand_name in unique_brands:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –º–∞—Ä–∫–∞
        brand = session.query(Brand).filter_by(name=brand_name).first()

        if not brand:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–∞—Ä–∫—É
            brand = Brand(
                name=brand_name,
                slug=brand_name.lower().replace(' ', '_').replace('-', '_')
            )
            session.add(brand)
            session.flush()  # –ü–æ–ª—É—á–∏—Ç—å ID

        brand_map[brand_name] = brand.id

    session.commit()
    return brand_map


def import_body_types(session: Session) -> dict:
    """
    –°–æ–∑–¥–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–∏–ø—ã –∫—É–∑–æ–≤–∞, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç.

    Returns:
        –°–ª–æ–≤–∞—Ä—å {code: id}
    """
    standard_body_types = [
        {'code': 'sedan', 'name_ru': '–°–µ–¥–∞–Ω'},
        {'code': 'hatchback', 'name_ru': '–•—ç—Ç—á–±–µ–∫'},
        {'code': 'suv', 'name_ru': '–í–Ω–µ–¥–æ—Ä–æ–∂–Ω–∏–∫'},
        {'code': 'minivan', 'name_ru': '–ú–∏–Ω–∏–≤—ç–Ω'},
        {'code': 'truck', 'name_ru': '–ì—Ä—É–∑–æ–≤–æ–π'},
        {'code': 'coupe', 'name_ru': '–ö—É–ø–µ'},
        {'code': 'wagon', 'name_ru': '–£–Ω–∏–≤–µ—Ä—Å–∞–ª'},
    ]

    body_type_map = {}

    for bt_data in standard_body_types:
        bt = session.query(BodyType).filter_by(code=bt_data['code']).first()

        if not bt:
            bt = BodyType(**bt_data)
            session.add(bt)
            session.flush()

        body_type_map[bt_data['code']] = bt.id

    session.commit()
    return body_type_map


def import_models(df: pd.DataFrame, session: Session, brand_map: dict, body_type_map: dict) -> dict:
    """
    –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π.

    Returns:
        –°–ª–æ–≤–∞—Ä—å {(brand, model, year_from, year_to): model_id}
    """
    model_map = {}

    for _, row in df.iterrows():
        brand_id = brand_map.get(row['brand'])
        body_type_id = body_type_map.get(row['body_type']) if row['body_type'] else None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        existing_model = session.query(Model).filter_by(
            brand_id=brand_id,
            name=row['model'],
            year_from=row['year_from'],
            year_to=row['year_to']
        ).first()

        if not existing_model:
            model = Model(
                brand_id=brand_id,
                name=row['model'],
                year_from=row['year_from'],
                year_to=row['year_to'],
                body_type_id=body_type_id,
                metadata={'source': 'pdf_import'}
            )
            session.add(model)
            session.flush()
            model_id = model.id
        else:
            model_id = existing_model.id

        key = (row['brand'], row['model'], row['year_from'], row['year_to'])
        model_map[key] = model_id

    session.commit()
    return model_map


def import_patterns(
    df: pd.DataFrame,
    session: Session,
    tenant_slug: str,
    category_code: str,
    model_map: dict
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å–∏ –ª–µ–∫–∞–ª (patterns) –¥–ª—è tenant.

    Args:
        tenant_slug: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∞—Ä–µ–Ω–¥–∞—Ç–æ—Ä–∞ (evopoliki, five_deluxe)
        category_code: –ö–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (eva_mats, car_covers, etc.)
    """
    # –ü–æ–ª—É—á–∞–µ–º tenant –∏ category
    tenant = session.query(Tenant).filter_by(slug=tenant_slug).first()
    category = session.query(ProductCategory).filter_by(code=category_code).first()

    if not tenant or not category:
        raise ValueError(f"Tenant '{tenant_slug}' or category '{category_code}' not found")

    for _, row in df.iterrows():
        key = (row['brand'], row['model'], row['year_from'], row['year_to'])
        model_id = model_map.get(key)

        if not model_id:
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ª–µ–∫–∞–ª–æ
        existing_pattern = session.query(Pattern).filter_by(
            tenant_id=tenant.id,
            category_id=category.id,
            model_id=model_id
        ).first()

        if not existing_pattern:
            pattern = Pattern(
                tenant_id=tenant.id,
                category_id=category.id,
                model_id=model_id,
                available=True,
                notes=row['description']  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            )
            session.add(pattern)

    session.commit()


def run_full_import(csv_path: str, tenant_slug: str, category_code: str = 'eva_mats'):
    """
    –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö.

    Usage:
        run_full_import('cleaned_vehicle_data.csv', 'evopoliki')
    """
    df = pd.read_csv(csv_path)

    with get_sync_session() as session:
        print("1. –ò–º–ø–æ—Ä—Ç –º–∞—Ä–æ–∫...")
        brand_map = import_brands(df, session)
        print(f"   –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–∞—Ä–æ–∫: {len(brand_map)}")

        print("2. –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫—É–∑–æ–≤–∞...")
        body_type_map = import_body_types(session)
        print(f"   –°–æ–∑–¥–∞–Ω–æ —Ç–∏–ø–æ–≤ –∫—É–∑–æ–≤–∞: {len(body_type_map)}")

        print("3. –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π...")
        model_map = import_models(df, session, brand_map, body_type_map)
        print(f"   –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(model_map)}")

        print("4. –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –ª–µ–∫–∞–ª...")
        import_patterns(df, session, tenant_slug, category_code, model_map)
        print(f"   –°–æ–∑–¥–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π –ª–µ–∫–∞–ª: {len(df)}")

    print("‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")


# –ó–∞–ø—É—Å–∫ –∏–º–ø–æ—Ä—Ç–∞
if __name__ == "__main__":
    run_full_import('cleaned_vehicle_data.csv', 'evopoliki', 'eva_mats')
```

---

## üìù –ü–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install pdfplumber pandas tabula-py
```

### –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PDF

```bash
python scripts/extract_pdf_data.py
# –°–æ–∑–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª: raw_vehicle_data.csv
```

### –®–∞–≥ 3: –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è

```bash
python scripts/clean_data.py
# –°–æ–∑–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª: cleaned_vehicle_data.csv
```

### –®–∞–≥ 4: –†—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```bash
# –û—Ç–∫—Ä–æ–π—Ç–µ CSV –≤ Excel/LibreOffice
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∞—Ä–æ–∫
# –î–æ–±–∞–≤—å—Ç–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ç–∏–ø—ã –∫—É–∑–æ–≤–∞ –≤—Ä—É—á–Ω—É—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
```

### –®–∞–≥ 5: –ò–º–ø–æ—Ä—Ç –≤ –ë–î

```bash
python scripts/import_to_database.py --tenant evopoliki --category eva_mats
```

### –®–∞–≥ 6: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è

```sql
-- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
SELECT COUNT(*) FROM brands;
SELECT COUNT(*) FROM models;
SELECT COUNT(*) FROM patterns WHERE tenant_id = 1;

-- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Å–≤—è–∑–µ–π
SELECT
    b.name AS brand,
    m.name AS model,
    bt.name_ru AS body_type,
    p.notes
FROM patterns p
JOIN models m ON p.model_id = m.id
JOIN brands b ON m.brand_id = b.id
LEFT JOIN body_types bt ON m.body_type_id = bt.id
WHERE p.tenant_id = 1
LIMIT 10;
```

---

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

1. **–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è:** –ü–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º —Å–¥–µ–ª–∞–π—Ç–µ backup –ë–î
   ```bash
   pg_dump car_chatbot > backup_before_import.sql
   ```

2. **–ü—Ä–æ–±–Ω—ã–π –∑–∞–ø—É—Å–∫:** –°–Ω–∞—á–∞–ª–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ 10-20 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

3. **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:** –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –ª–æ–≥–∏ –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
   ```python
   import logging
   logging.basicConfig(filename='import.log', level=logging.INFO)
   ```

4. **–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è:** –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –Ω–∞–ª–∏—á–∏–µ –¥—É–±–ª–µ–π –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ

5. **–í–∞–ª–∏–¥–∞—Ü–∏—è:** –ü–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö:
   - –í—Å–µ –ª–∏ –º–∞—Ä–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã?
   - –í—Å–µ –ª–∏ –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ foreign keys?
   - –í—Å–µ –ª–∏ patterns —Å–≤—è–∑–∞–Ω—ã —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏?

---

## üîÑ –î–∞–ª—å–Ω–µ–π—à–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞:

1. **–ò–º–ø–æ—Ä—Ç —Ü–µ–Ω** –∏–∑ –æ—Ç—á–µ—Ç–∞ –ø–æ –≤—Å—Ç—Ä–µ—á–µ –≤ —Ç–∞–±–ª–∏—Ü—É `prices`
2. **–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö** –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ tenant (five_deluxe)
3. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏** –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏
4. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –±–æ—Ç–æ–º** –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —à–∞–≥–æ–≤:

- ‚úÖ **~50-100** —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ `brands`
- ‚úÖ **~900+** –º–æ–¥–µ–ª–µ–π –≤ —Ç–∞–±–ª–∏—Ü–µ `models`
- ‚úÖ **7** —Ç–∏–ø–æ–≤ –∫—É–∑–æ–≤–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ `body_types`
- ‚úÖ **~900+** –∑–∞–ø–∏—Å–µ–π –ª–µ–∫–∞–ª –≤ —Ç–∞–±–ª–∏—Ü–µ `patterns` (–¥–ª—è tenant evopoliki)
- ‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

---

**–í–µ—Ä—Å–∏—è:** 1.0
**–ê–≤—Ç–æ—Ä:** Claude
**–î–∞—Ç–∞:** 2025-01-09

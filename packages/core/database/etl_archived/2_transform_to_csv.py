#!/usr/bin/env python3
"""
ETL Pipeline - Step 2: TRANSFORM
=================================
–ü–∞—Ä—Å–∏—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –∏–∑ output/raw_text.txt,
–ø—Ä–∏–º–µ–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö,
—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ output/patterns_clean.csv

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python 2_transform_to_csv.py

–†–µ–∑—É–ª—å—Ç–∞—Ç:
    –°–æ–∑–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª ../output/patterns_clean.csv
    —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: brand, model, category, available
"""

import sys
import csv
import re
from pathlib import Path
from typing import List, Dict, Set

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(Path(__file__).parent.parent))


class DataTransformer:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö."""

    def __init__(self):
        self.patterns = []
        self.seen = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤

    def clean_brand_name(self, brand: str) -> str:
        """
        –û—á–∏—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä.
        """
        brand = brand.strip()
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        brand = " ".join(brand.split())
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–≥–∏—Å—Ç—Ä: –ø–µ—Ä–≤–∞—è –±—É–∫–≤–∞ –∑–∞–≥–ª–∞–≤–Ω–∞—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ—á–Ω—ã–µ
        # –ö—Ä–æ–º–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä —Ç–∏–ø–∞ KIA ‚Üí Kia
        brand = brand.capitalize()
        return brand

    def clean_model_name(self, model: str, brand: str) -> str:
        """
        –û—á–∏—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:
        - –£–±–∏—Ä–∞–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å –±—Ä–µ–Ω–¥–∞ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        - –£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–∏–º–≤–æ–ª—ã
        """
        model = model.strip()

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –±—Ä–µ–Ω–¥–∞ (—Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã)
        prefixes_to_remove = [
            f"{brand} ",
            f"{brand}-",
            f"{brand}_",
            f"{brand.upper()} ",
            f"{brand.lower()} ",
        ]

        for prefix in prefixes_to_remove:
            if model.startswith(prefix):
                model = model[len(prefix):].strip()
                break

        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        model = " ".join(model.split())

        return model

    def parse_text(self, text: str) -> List[Dict[str, str]]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –∏–∑ PDF-—Ç–∞–±–ª–∏—Ü—ã.

        –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç:
        ID –ú–∞—Ä–∫–∞ –ú–æ–¥–µ–ª—å –ì–æ–¥ –û–ø–∏—Å–∞–Ω–∏–µ
        359 –î–∞–π—Ö–∞—Ç—Å—É –ö—É–∞—Ä–µ - 1 –ø–æ–∫–æ–ª–µ–Ω–∏–µ —Å –±–æ—Ä—Ç–∞–º–∏
        218 Honda –ò–Ω—Å–ø–∞–π–µ—Ä 1999 —Å—Ä–µ–¥–Ω–∏–π –±–æ—Ä—Ç 1 –∫—É–∑–æ–≤
        """
        print("\nüîÑ –ü–ê–†–°–ò–ù–ì –î–ê–ù–ù–´–•")
        print("=" * 70)

        lines = text.split('\n')
        patterns_count = 0

        for line in lines:
            line = line.strip()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –º–µ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if not line or line.startswith('===') or line.startswith('ID –ú–∞—Ä–∫–∞'):
                continue

            words = line.split()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å ID (—á–∏—Å–ª–∞)
            if len(words) >= 3 and words[0].isdigit():
                # –§–æ—Ä–º–∞—Ç: ID –ú–∞—Ä–∫–∞ –ú–æ–¥–µ–ª—å [–ì–æ–¥ –û–ø–∏—Å–∞–Ω–∏–µ...]
                # words[0] = ID (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
                # words[1] = –ú–∞—Ä–∫–∞
                # words[2] = –ú–æ–¥–µ–ª—å

                brand_raw = words[1]
                model_raw = words[2]

                # –û—á–∏—â–∞–µ–º –±—Ä–µ–Ω–¥ –∏ –º–æ–¥–µ–ª—å
                brand = self.clean_brand_name(brand_raw)
                model = self.clean_model_name(model_raw, brand)

                # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if brand and model and brand != '-' and model != '-':  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–±–∞ –Ω–µ –ø—É—Å—Ç—ã–µ –∏ –Ω–µ –ø—Ä–æ—á–µ—Ä–∫–∏
                    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                    key = f"{brand}|{model}".lower()

                    if key not in self.seen:
                        self.seen.add(key)

                        pattern = {
                            'brand': brand,
                            'model': model,
                            'category': 'eva_mats',  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                            'available': 'true'
                        }

                        self.patterns.append(pattern)
                        patterns_count += 1

                        if patterns_count % 100 == 0:
                            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {patterns_count}", end="\r")

        print(f"\n\n‚úÖ –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(self.patterns)}")
        return self.patterns

    def save_to_csv(self, patterns: List[Dict[str, str]], output_path: Path):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª.
        """
        print("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –í CSV")
        print("=" * 70)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –±—Ä–µ–Ω–¥—É –∏ –º–æ–¥–µ–ª–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        patterns_sorted = sorted(patterns, key=lambda x: (x['brand'], x['model']))

        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['brand', 'model', 'category', 'available']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            writer.writeheader()
            writer.writerows(patterns_sorted)

        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(patterns_sorted)}")
        print(f"üìÅ –§–∞–π–ª: {output_path}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        print("\nüìä –ü–†–ò–ú–ï–†–´ –ó–ê–ü–ò–°–ï–ô:")
        for i, pattern in enumerate(patterns_sorted[:10], 1):
            print(f"   {i}. {pattern['brand']} {pattern['model']}")

        if len(patterns_sorted) > 10:
            print(f"   ... –∏ –µ—â–µ {len(patterns_sorted) - 10} –∑–∞–ø–∏—Å–µ–π")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("=" * 70)
    print("üîÑ ETL PIPELINE - STEP 2: TRANSFORM")
    print("=" * 70)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    input_path = project_root / "output" / "raw_text.txt"
    output_path = project_root / "output" / "patterns_clean.csv"

    if not input_path.exists():
        print(f"\n‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python 1_extract_raw_text.py")
        sys.exit(1)

    # –ß–∏—Ç–∞–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
    print(f"\nüìñ –ß—Ç–µ–Ω–∏–µ: {input_path}")
    with open(input_path, 'r', encoding='utf-8') as f:
        raw_text = f.read()

    print(f"   –†–∞–∑–º–µ—Ä: {len(raw_text):,} —Å–∏–º–≤–æ–ª–æ–≤")

    # –ü–∞—Ä—Å–∏–º –∏ –æ—á–∏—â–∞–µ–º
    transformer = DataTransformer()
    patterns = transformer.parse_text(raw_text)

    if not patterns:
        print("\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞!")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ raw_text.txt")
        sys.exit(1)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    transformer.save_to_csv(patterns, output_path)

    print("\n" + "=" * 70)
    print("‚úÖ –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 70)
    print(f"\n–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: python 3_load_from_csv.py")


if __name__ == "__main__":
    main()
